<img src="utils/Image.jpg" width="100%" height="auto" />
<div align="center">
<img src="https://readme-typing-svg.demolab.com?font=Courgette&size=28&pause=6000&center=true&width=435&height=55&lines=Hello+All...!" />
  <br>
<img src="https://readme-typing-svg.demolab.com?font=Courgette&size=28&pause=6000&width=600&height=55&lines=%E2%98%86+This+is+Rohit%2C+Turning+data+into+magic+%E2%98%86" alt="Typing SVG" />
</div> 
<br>
<div align="left">

## ðŸš€ `About Me`
Results-driven, GCP Cloud Data Engineer and Python Developer with over 2.5 years of experience at Capgemini, specializing inREST API development using Flask and Django. Skilled in designing and implementing end-to-end data pipelines on Google CloudPlatform (GCP) with tools like Cloud Dataflow (Apache Beam) and Cloud Composer (Airflow). Proficient in ETL processes, datamigration, working with relational databases such as SQL and Spanner, as well as Big Data technologies like BigQuery and NoSQLdatabases such as MongoDB. Expertise in data processing, storage, and retrieval, with advanced Python skills, leveraging pandas andPySpark for data manipulation and analysis. 

## ðŸ”§ `Technologies & Tools`
- **Languages/Databases:** Python, SQL, PySpark, HTML, terraform, shell Scripting (unix), mongoDB
- **Cloud/Bigdata:** GCP (data Flow, Composer, Dataproc, bigQuery, pub/sub), Databricks , snowflake, kafka
- **Frameworks:** Flask, Django
- **Libraries:** pandas, NumPy, Matplotlib, Requests, csv, Json, Streamlit, sqlite
- **CI/CD Testing:** Pytest, unittest, postman, jenkins, Docker, GIT


## ðŸ“‚ `My Projects`
**1. *CCA Data Engineer [Dec 2024 â€“ Present ]** 
- Architected resilient serverless data pipelines leveraging Cloud Run, Cloud Functions, and Cloud Pub/Sub, processing 500,000+daily events with 99.99% uptime and minimal latency, ensuring reliable data delivery. 
- Implemented Infrastructure as Code (IaC) using Terraform, automating cloud resource provisioning and management, reducing deployment time by 60%. 
- Created a Python script to automate fetching, processing, and retransmitting 1,000+ payloads affected by pip.


**2. *CDS Developer [ Jan 2024 â€“ Dec 2024 ]** 
- Developed and maintained 24+ REST APIs across 7+ API groups, resolving 50+ critical bugs and performance issues, improvingresponse times by 40%.
- Successfully led the go-live of one market, collaborating with a team comprising one architect and one tester.
- Automated daily batch data exports using Apache Airflow DAGs, eliminating manual intervention and ensuring timely datadelivery to 10+ upstream systems.
- Engineered batch data pipelines processing thousands of records daily with 99.98% reliability, utilizing Dataflow, Cloud Run, Cloud Functions, and Pub/Sub.
- Contributed to the migration of large volumes of historical data to Cloud Spanner. 
- Independently resolved a security breach by modifying Dataflow code for 180+ batch jobs, ensuring secure and compliant secret management


**3. *Data Engineer [ Nov 2023 â€“ Dec 2024 ]**
- Optimized batch data pipelines on Cloud Run & BigQuery, enabling the processing of 20+ terabytes of data within a sub-3-hourservice level agreement, satisfying critical stakeholder requirements.


**4. *Pyspark Application using Python**
- Skills : Python, Pyspark, SQL, Logging, Pytest , GitHub
- Built a PySpark-based ETL pipeline designed to read, transform, and stream data to upstream systems using Kafka.
- <a href="https://github.com/Rohit-Sandanshiv/pyspark_kafka_project" target="_blank">Check Code here</a>


**5. *REST API using Flask and requests**
- skills: Python , Flask, SQLite, requests, JSON , GitHub
- Consumer Management API: This is a simple Flask-based REST API for managing consumers, products, and purchases. It supports adding, updating, and retrieving consumer details using POST and GET requests via Pythonâ€™s requests module.
- [Check Code here](https://github.com/Rohit-Sandanshiv/python_api)


**6. *Django Cloud-Run Project**
- Python, Django, Cloud Run, Cloud Run Functions, Pub/Sub, Dataflow , Docker, GitHub
- Purchase API hosted on Cloud Run, loading data into MongoDB database using a Dataflow, Cloud Functions, and Pub/Sub.
- [Check Code here](https://github.com/Rohit-Sandanshiv/django_cloudRun_Project) 



## ðŸŽ“ `Education`
- **College of Engineering, Pune(COEP) - Pune**
- **B. Tech. Mechanical Engineering**
- **Graduation:** May 2022
- **CGPA:** 8.16/10
- **Honours Degree:** Automotive Engineering

## `COURSES & CERTIFICATIONS`
- **Associate Cloud Engineer certification**
- **The Complete SQL Bootcamp - Udemy**
- **Python programming for Everybody -(Coursera University of Michigan)**
- **Google cloud professional data engineer course â€“ Udemy**
- **Apache-spark-programming-in-python-for-beginners -Udemy**
- **terraform-for-beginners-using-google-cloud - Udemy**


## ðŸ“„ `Resume`
[Check here](utils/Rohit_Sandanshiv_Resume.pdf)

## `Connect With me`
Reach out to me **rssandanshiv782000@gmail.com**

Linkdin :**https://www.linkedin.com/in/rohit-sandanshiv-0785a71a7/**

Hackerrank: **https://www.hackerrank.com/profile/rssandanshiv7821**

<pre align="center">ðŸŒŸ Keep leveling up in the world of data & code! ðŸŒŸ</pre>
<br><br><br>
</div>
